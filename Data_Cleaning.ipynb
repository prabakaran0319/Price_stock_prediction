{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"FAANG.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Empty columns are removed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"Revenue\",\"Gross Profit\",\"Operating Income\",\"Cash Ratio\",\"Total Assets\",\"Total Equity\",\"Trailing Twelve Months (TTM) Revenue\",\"Trailing Twelve Months (TTM) EBITDA\",\"Trailing Twelve Months (TTM) Earnings\"],inplace = True)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Change the date format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing the NaN values for these columns with their respective mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names into list\n",
    "columns_to_fill = [\"Beta\", \"Dividends Paid\", \"Dividend Yield\", \"Beta (5Y)\", \"Annual Dividend Rate\"]\n",
    "\n",
    "# Fill NaN values in each specified column with the column's mean\n",
    "for column in columns_to_fill:\n",
    "    df[column] = df[column].fillna(df[column].mean())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mean values filled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Beta\", \"Dividends Paid\", \"Dividend Yield\", \"Beta (5Y)\", \"Annual Dividend Rate\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**no null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding unique values for these three columns,remaining columns are numerical.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is no need to use Mode Imputation method(Fill with the most frequent value) for these categorical columns, because there is no none value in these below columns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Company\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Ticker\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Analyst Recommendation\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One_Hot_Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the categorical columns to change into numerical columns..in this dataset we have only three categorical columns named Company,Ticker and \n",
    "Analyst Recommendation. The Company and Ticker columns both are nominal values because,They are just names or labels without any inherent order or ranking.\n",
    "Analyst Recommendation is also nominal because it doesn't have an inherent order or ranking between values like \"buy\", \"sell\", or \"hold\".But, if it had something like - \"Strong Buy\", \"Buy\", \"Hold\", \"Sell\" Then, it could be considered ordinal because there's a natural order (stronger to weaker recommendation).In this case, nominal is the right category for Analyst Recommendation.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This code will create separate columns for each unique value in the 'Company' and 'Ticker' columns (like 'Company_Apple', 'Company_Facebook', etc.).\n",
    "drop_first=False keeps all categories as separate columns, which is fine, \n",
    "though sometimes itâ€™s recommended to set drop_first=True to avoid the dummy variable trap (multicollinearity).\"\"\"\n",
    "# Apply One-Hot Encoding for 'Company' and 'Ticker'\n",
    "df = pd.get_dummies(df, columns=['Company', 'Ticker'], drop_first=False)\n",
    "\n",
    "# Select only the one-hot encoded columns and convert them to integers\n",
    "df[df.columns[df.dtypes == 'bool']] = df[df.columns[df.dtypes == 'bool']].astype(int)\n",
    "\n",
    "\"\"\"Since all values in the 'Analyst Recommendation' column are \"buy\", you can replace this column with a constant value\n",
    "no need to use Label encoding because it is not necesarry\"\"\"\n",
    "# Optionally replace 'Analyst Recommendation' with a constant value (e.g., 0)\n",
    "df['Analyst Recommendation'] = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Re-Ordering the columns in data frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically get the list of encoded columns (those that start with 'Company_' or 'Ticker_')\n",
    "encoded_columns = [col for col in df.columns if col.startswith('Company_') or col.startswith('Ticker_')]\n",
    "\n",
    "# Get the remaining columns (those that are not one-hot encoded)\n",
    "remaining_columns = [col for col in df.columns if col not in encoded_columns]\n",
    "\n",
    "# Reorder the DataFrame with encoded columns first\n",
    "df = df[encoded_columns + remaining_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**correlation checking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows\n",
    "pd.set_option('display.max_columns', None)  # Show all columns\n",
    "pd.set_option('display.width', 1000)  # Avoid line breaks\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent truncation\n",
    "\n",
    "print(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (27,20))\n",
    "sns.heatmap(df.corr(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**these columns wont do any significane difference in prediction so i removed it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\n",
    "    \"Open\",\n",
    "    \"High\",\n",
    "    \"Low\",\n",
    "    \"Analyst Recommendation\",\n",
    "    \"Adj Close\",\n",
    "    \"Ticker_AAPL\",\n",
    "    \"Ticker_AMZN\",\n",
    "    \"Ticker_GOOGL\",\n",
    "    \"Ticker_META\",\n",
    "    \"Ticker_NFLX\",\n",
    "    \"Beta\"\n",
    "],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_visualization(df, column):\n",
    "    # Check if the column is numeric before plotting the boxplot\n",
    "    if df[column].dtype in ['float64', 'int64']:  # Only plot boxplot for numeric columns\n",
    "        # Line Chart: Show trends in stock prices over time\n",
    "        plt.figure(figsize=(15, 4))\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.plot(df['Date'], df[column], label=f'{column} Trend', color='blue')\n",
    "        plt.title(f\"Line Chart for {column}\")\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(f'{column}')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.legend()\n",
    "\n",
    "        # Box Plot: Detect outliers in price and volume\n",
    "        plt.subplot(1, 4, 2)\n",
    "        sns.boxplot(x=df[column], color='orange')\n",
    "        plt.title(f\"Box Plot for {column}\")\n",
    "\n",
    "        # Histogram: Distribution of values for the column\n",
    "        plt.subplot(1, 4, 3)\n",
    "        sns.histplot(df[column], kde=True, bins=30, color='salmon')\n",
    "        plt.title(f\"Histogram for {column}\")\n",
    "\n",
    "        # Scatter Plot: Visualize relationships between stock prices and volume\n",
    "        plt.subplot(1, 4, 4)\n",
    "        sns.scatterplot(x=df[column], y=df['Volume'], color='green')\n",
    "        plt.title(f\"Scatter Plot for {column}\")\n",
    "        plt.xlabel(f'{column}')\n",
    "        plt.ylabel('Volume')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        # If the column is not numeric, skip the boxplot and scatter plot\n",
    "        print(f\"Skipping {column} because it is not numeric.\")\n",
    "\n",
    "# To apply to all columns:\n",
    "columns = df.columns  # List all columns\n",
    "for column in columns:\n",
    "    data_visualization(df, column)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers_handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to keep the original df and compare changes, use df1\n",
    "df1 = df.copy()  # Create a copy of df for comparison\n",
    "# Define the numeric columns to check for outliers\n",
    "numeric_columns = ['Close', 'Volume']\n",
    "\n",
    "# Function to remove outliers using IQR for a single column (with added print statements)\n",
    "def remove_outliers_iqr(df, column):\n",
    "    Q1 = df[column].quantile(0.25)  # 25th percentile (Q1)\n",
    "    Q3 = df[column].quantile(0.75)  # 75th percentile (Q3)\n",
    "    IQR = Q3 - Q1  # Interquartile Range\n",
    "    lower_bound = Q1 - 1.5 * IQR  # Lower limit\n",
    "    upper_bound = Q3 + 1.5 * IQR  # Upper limit\n",
    "\n",
    "    # Print out the values for debugging\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Q1: {Q1}, Q3: {Q3}, IQR: {IQR}\")\n",
    "    print(f\"Lower Bound: {lower_bound}, Upper Bound: {upper_bound}\")\n",
    "\n",
    "    # Filter out rows where the value is outside the bounds\n",
    "    filtered_df = df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "    \n",
    "    # Print number of rows before and after filtering\n",
    "    print(f\"Rows before: {len(df)}, Rows after: {len(filtered_df)}\")\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "# Apply the function to check for outliers\n",
    "for column in numeric_columns:\n",
    "    df1 = remove_outliers_iqr(df1, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns:\n",
    "    data_visualization(df1, column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We are going to calculate the Z-score for each value in the numeric columns and filter out those with Z-scores greater than 3 or less than -3.\n",
    "We keep only those rows where the Z-score is between -3 and 3, which removes data points that are too far from the mean (outliers).\n",
    "We already filtered the outliers using IQR and now we are filtering with Z-score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Define the numeric columns to apply Z-score\n",
    "numeric_columns = ['Close', 'Volume']\n",
    "\n",
    "# Function to remove outliers using Z-score\n",
    "def remove_outliers_zscore(df, column, threshold=3):\n",
    "    # Calculate Z-scores for the column\n",
    "    z_scores = stats.zscore(df[column])\n",
    "    \n",
    "    # Print out the mean and std for debugging\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Mean: {df[column].mean()}, Std: {df[column].std()}\")\n",
    "    \n",
    "    # Filter out rows where Z-score is greater than threshold (outliers)\n",
    "    df_no_outliers = df[(z_scores < threshold) & (z_scores > -threshold)]\n",
    "    \n",
    "    # Print number of rows before and after filtering\n",
    "    print(f\"Rows before: {len(df)}, Rows after: {len(df_no_outliers)}\")\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "# Apply the function to remove outliers using Z-score\n",
    "for column in numeric_columns:\n",
    "    df1 = remove_outliers_zscore(df1, column)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**re-order index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned DataFrame to a CSV file\n",
    "df1.to_csv('cleaned_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
